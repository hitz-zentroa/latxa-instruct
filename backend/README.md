# Backend

This directory contains scripts and configuration files for launching and managing AI model servers used in the Latxa-Instruct project.

## Contents

- `launcher_partial.sh`: Script to launch multiple model servers across different GPUs and generate a configuration file with their endpoints.
- `start_server_partial.sh`: Script to start a single model server with the specified model, port, and GPU.
- `partial_config.jsonl`: JSON Lines file containing the configuration (model name, host, port, job ID) for each running model server. This file is generated by `launcher_partial.sh` and used by the frontend to connect to the models.
- `README.md`: This documentation file.

## Usage

> [!WARNING]
> The environment in `start_server_partial.sh`must be set up correctly with all necessary dependencies installed. Ensure you have the required permissions to run the scripts and access the GPUs.


Use `launcher_partial.sh` to start all required model servers. The script detects the server environment and launches the appropriate models on available GPUs, each in its own screen session. It also generates the `partial_config.jsonl` file.

```sh
./backend/launcher_partial.sh
```

## Notes

- Ensure all dependencies and environment variables are set up as required by your model servers.
- The scripts use `screen` to manage background processes and log output to `.slurm/` log files.
- The backend is designed to work with the frontend in the `../frontend` directory, which reads `partial_config.jsonl` to discover available models.

For more details, see comments in each script.

